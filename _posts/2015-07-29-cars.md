---
layout: post_page
title: cars scatterplot and regression experiments
---

Here I investigate the relationship between car speed and stop distance in feet. Data from 1920s.

Also, I'm finally getting into regression visualization!

	> data()
	> head(cars)
	  speed dist
	1     4    2
	2     4   10
	3     7    4
	4     7   22
	5     8   16
	6     9   10
	> tail(cars)
	   speed dist
	45    23   54
	46    24   70
	47    24   92
	48    24   93
	49    24  120
	50    25   85
	> attach(cars) #why attach? makes easier to access without explicitly recalling, I think
	> plot(speed,dist,main="brake performance",xlab="speed",ylab="dist",pch=19)

![Scatterplot](/images/breakperformance.png)

	> abline(lm(dist~speed),col="red") #regression line
	> lines(lowess(speed,dist),col="blue") #lowess
	#note: lowess smoothing is best when line of best is hard to determine
	#or lease squares fitting doesn't create a good line of best fit

![Scatterplot](/images/BPregression.png)

Ok so I admit, I obviously have no idea what I'm doing in regards to regression, but then again, I don't really know what I'm doing in any other sense. Keep on learning and experimenting!

I promise I'll be better at statistics within a year.

I checked with the R documentation, and here is what they have, as a note to myself for later:

	> plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
	+     las = 1, xlim = c(0, 25))
	> d <- seq(0, 25, length.out = 200)
	> for(degree in 1:4) {
	+   fm <- lm(dist ~ poly(speed, degree), data = cars)
	+   assign(paste("cars", degree, sep = "."), fm)
	+   lines(d, predict(fm, data.frame(speed = d)), col = degree)
	+ }
	> anova(cars.1, cars.2, cars.3, cars.4)
	Analysis of Variance Table

	Model 1: dist ~ poly(speed, degree)
	Model 2: dist ~ poly(speed, degree)
	Model 3: dist ~ poly(speed, degree)
	Model 4: dist ~ poly(speed, degree)
	  Res.Df   RSS Df Sum of Sq      F Pr(>F)
	1     48 11354                           
	2     47 10825  1    528.81 2.3108 0.1355
	3     46 10634  1    190.35 0.8318 0.3666
	4     45 10298  1    336.55 1.4707 0.2316

![Scatterplot](/images/bpregression4.png)

It looks like they assigned a polynomial regression. After looking into this a bit, I realized I should really be looking at r-squared, d.f., and P values to really determine fit.

So looking into how to find r-squared, I tried this:

	> summary(lm(dist~speed))$r.squared #regression line
	[1] 0.6510794
	> summary(lowess(speed,dist))$r.squared #and naturally the lowess line
	Error in summary(lowess(speed, dist))$r.squared : 
  	$ operator is invalid for atomic vectors 

But why is this invalid? $ only valid for recursive objects. Ok, let's go another direction, P value, which should be a better indicator of fit.

My t-test for cars revealed this:

	> t.test(cars)

		One Sample t-test

	data:  cars
	t = 12.625, df = 99, p-value < 2.2e-16
	alternative hypothesis: true mean is not equal to 0
	95 percent confidence interval:
	 24.60221 33.77779
	sample estimates:
	mean of x 
	    29.19 

I'll make this a question for next time: how to get measures of fit like P value along with lines of regression? Like [this site](http://www.dmi.units.it/~inverniz/adir/statcurvreg.html) did.

